\section{Fundamentos del Aprendizaje Automático}

Pese a que es fácil reconocer un árbol en una imagen, la descripción precisa de que es un árbol es prácticamente imposible. La tarea se hace aún más difícil cuando tenemos que especificar estos detalles para una computadora. Aún así, se ha conseguido completar esta tarea, gracias al Aprendizaje Automático.\\

El Aprendizaje Automático es la rama de la informática que trata el estudio y la creación de algoritmos que puedan aprender automáticamente de los datos.\\

En esta sección seguiremos fundamentalmente el libro de Abu-Mostafa \cite{Abu-Mostafa:2012:LD:2207825} para la introducción a los conceptos más importantes del Aprendizaje Automático.\\

\subsection{Tipos de Aprendizaje Automático}

La premisa básica del aprendizaje es el uso de un conjunto de oobservaciones para tratar de descubrir el proceso que hay detrás de las mismas. Esto es una premisa muy amplia, por lo que se divide en varios paradigmas, cada uno centrado en diferentes situaciones.\\

En esta apartado se tratarán los paradigmas más importantes, destacando el aprendizaje supervisado ya que es el más estudiado y utilizado, y además es el paradigma en el que encaja la clasificación automática en etiquetas de imágenes, objetivo de este trabajo.\\

\subsubsection{Aprendizaje supervisado}

Cuando el conjunto de datos contiene de manera explícita la salida correcta para el dato, nos encontramos ante un caso de aprendizaje supervisado. Por ejemplo, supongamos una base de datos para el reconocimiento de dígitos escritos a mano. Sería razonable que la base de datos se compusiera de imágenes con ejemplos de dígitos escritos a mano y el dígito escrito en cada imagen, obteniendo un conjunto de parejas imagen y dígito.\\
 
Lo común dentro de este caso es que se presente la base de datos en su totalidad, pero existen otras opciones.\\

Por un lado, encontramos el aprendizaje activo, donde el conjunto de datos se obtiene mediante consultas. En este paradigma, se elige el punto x del espacio de entrada y se obtiene la salida de x. Esto permite una elección estratégica de de los puntos para maximizar el aprendizaje\\

Por otro lado, encontramos el aprendizaje online. En esta ocasión, los datos se presentan de uno en uno. Por ejemplo, este caso se puede dar cuando admitimos nuevos datos durante ejecución, permitiendo la entrada de un dato y su clasificación, adaptando el modelo en consecuencia. También es de utilidad cuando tenemos limitaciones de computación o almacenamiento, permitiendo procesar los datos cuando no podemos procesar la base de datos completa. Destacar que el aprendizaje online puede ser usado en diferentes paradigmas del aprendizaje, y no sólo en el aprendizaje supervisado.\\

\subsubsection{Aprendizaje por refuerzo}

En cuanto no disponemos explícitamente de la salida correcta para un dato, no nos encontramos en el caso del aprendizaje supervisado. Aún así, hay situaciones en las que pese a no tener una salida a priori, podemos tener un grado de acierto de la acción. Por ejemplo, supongamos a un bebe aprendiendo que hacer ante un objeto caliente. El bebe tendría dos opciones, tocar o no tocar el objeto. Si no toca el objeto, la insatisfacción de su curiosidad le producirá algo de mal estar. Si lo toca, el dolor será mayor. Pese a que el objeto no presenta claramente la respuesta al problema del bebe, tras varios intentos aprenderá que es mejor no tocar el objeto.\\

Esto caracteriza el aprendizaje por refuerzo, donde los datos no presentan claramente el resultado, pero si contienen una posible salida junto con una medida de la bondad de la salida, a diferencia del aprendizaje supervisado que contiene únicamente el dato y la salida. Es importante destacar que en el aprendizaje por refuerzo no sabemos la bondad de las demás posibles salidas.\\

El aprendizaje por refuerzo es usado principalmente para aprender a jugar a un juego. Por ejemplo, en una partida de ajedrez tienes que elegir entre un conjunto de movimientos para tomar la mejor acción. Sin embargo, es muy difícil, dada una situación de la partida decidir cuál es la mejor acción, haciendo imposible la generación de un ejemplo para el aprendizaje supervisado. Sin embargo, es muy fácil generar un ejemplo de aprendizaje por refuerzo, simplemente hay que tomar una acción y luego, informar del resultado de la misma. Tras esto, es el algoritmo de aprendizaje por refuerzo el que analiza la información para tratar de encontrar la mejor jugada.\\

\subsubsection{Aprendizaje no supervisado}

El caso del aprendizaje no supervisado es en el que los datos no contienen ninguna información de la salida. En un principio, al no disponer de una salida esperada para los datos, parecería que no es posible aprender nada de los mismos. Sin embargo, este caso incluye el análisis de clúster o clustering. En él se pretende clasificar los datos en diferentes conjuntos o clústers, de manera que en cada conjunto tengamos elementos parecidos entre ellos.\\

Además de su utilidad propia para detectar patrones y estructuras ocultas dentro de los datos, se puede utilizar como fase previa para un proceso de aprendizaje supervisado \cite{lecun-nature} para mejorar el comportamiento final del sistema.\\

\subsection{Componentes del Aprendizaje Automático}

Empecemos con un ejemplo de un caso de aprendizaje automático, para poder dividirlo en sus diferentes componentes. Supongamos un banco que quiere procesar de manera automática la concesión de créditos a sus usuarios. El banco no conoce la fórmula para aceptar o no los créditos, pero sí tiene una gran base de datos de operaciones ya realizadas.\\

Por tanto, siendo x la información de una nueva petición de crédito, el objetivo es encontrar la función desconocida $f: \mathcal{X} \rightarrow \mathcal{Y}$ donde $\mathcal{X}$ es el espacio de entrada, todas las posibles peticiones de crédito e $\mathcal{Y}$ todas las posibles salidas, en este caso sí o no, según se acepte o no el crédito. Disponemos de un conjunto de datos $\mathcal{D}$ formado por parejas de ejemplos de entrada y salida $(x_1,y_1),\ldots,(x_N,y_N)$, donde $f(x_n)=y_n, $ para $ n = 1,\ldots,N$. Existe también un conjunto de funciones $\mathcal{H}$, conocido como el conjunto de hipótesis, que es el conjunto de funciones que consideramos para aproximar a la función desconocida $f$. Por último, tenemos un algoritmo de aprendizaje que trata de obtener la función $g$ dentro de $\mathcal{H}$, con el objetivo de aproximar $f$.\\

Las nuevas peticiones de crédito serán evaluadas mediante la función $g$, no con la función $f$ que es desconocida. Por tanto, el buen resultado del sistema depende de la capacidad de $g$ en aproximar a $f$, luego el algoritmo de aprendizaje tratará de buscar la función $g$ que mejor aproxima a $f$ dentro de los datos de entrenamiento, $\mathcal{D}$. Tras esto, solo queda esperar que pueda aproximar bien los datos fuera de la muestra de entrenamiento, de lo que no tenemos ninguna información.\\

\subsection{¿Es posible aprender?}

La función $f$ es el objetivo del aprendizaje. La restricción más importante sin duda es la de ser completamente desconocida. Esto genera preguntas rápidamente, siendo quizás la primera que puede venir a la mente la que da título a este apartado. ¿Es posible aprender mediante un conjunto de ejemplos?\\

Todos recordamos los pequeños puzzles consistentes en encontrar los siguientes números de una sucesión dada, encontrando la función que los genera. Si bien es cierto que, desde un punto de vista matemático, cualquier sucesión de números que demos como respuesta es una sucesión válida, se busca una respuesta mediante el uso de una regla simple. Pero estos puzzles requieren claramente una cantidad suficiente de información para obtener la respuesta. Un ejemplo de esta necesidad sería la sucesión ${2,4,\ldots}$. Con tan poca información, se nos pueden ocurrir muchas explicaciones distintas, y por tanto continuaciones distintas a la sucesión, siendo quizás las dos más evidentes la de ser todos los números pares o la de ser potencias de 2.\\

Esto se debe claramente a que hay más de una sucesión que puede se inicia con ese fragmento de sucesión. Este simple ejemplo pone en entredicho la posibilidad de aprender. Y para complicar más las cosas, este ejemplo no es una excepción. Podemos generar problemas de este tipo con todo tipo de problemas donde varias de las posibles funciones del conjunto $\mathcal{H}$ aciertan en toda la muestra $\mathcal{D}$.\\

Ahora bien, teniendo claro que no podemos asegurar el funcionamiento de nuestra estimación fuera de la muestra $\mathcal{D}$, podemos utilizar la probabilidad para tratar de dar una medida del acierto de la aproximación fuera de la muestra.\\

Para ello, vamos a utilizar un problema clásico dentro de la estadística y la probabilidad. Supongamos que tenemos una bolsa con infinitas bolas blancas y negras. La proporción entre bolas blancas y negras hace que la probabilidad de tomar una bola negra sea $\mu$, mientras que la probabilidad de obtener una bola blanca será $1-\mu$. Asumimos que desconocemos este parámetro $\mu$. Para tratar de estimarlo, tomamos una muestra de $N$ bolas independientes, con reemplazamiento. Observamos la fracción de bolas negras en la muestra, que será nuestra estimación de $\mu$. ¿Qué nos dice esta fracción, a la que llamaremos $\nu$, sobre $\mu$?.\\

Para cuantificar la relación entre $\nu$ y $\mu$, vamos a usar una cota, llamada la inecuación de Hoeffding. Dice que, para cualquier tamaño de muestra $N \in \mathbb{N}$,\\
\[
\ \mathbb{P}\left[ \mid \nu - \mu \mid > \epsilon \right] \leq 2e^{-2\epsilon^2 N} \qquad \textrm{para todo} \  \epsilon > 0.
\]

Esta inecuación nos da una información muy importante para nuestro problema. Podemos aumentar la probabilidad de que $\nu$ esté a una distancia de $\mu$ menor que $\epsilon$ simplemente aumentando el número de muestras $N$. Esto nos da una medida de la confianza que podemos tener en nuestra estimación para nuevos datos. Es decir, nos dice que podemos aprender, pero que jamás tendremos la certeza absoluta de que lo que aprendemos sea correcto. Solo podemos hablar en términos de que es muy probable que la aproximación sea correcta con un tamaño suficiente de los datos.\\

Este ejemplo, lo podemos adaptar a nuestro problema de aprendizaje. Simplemente, cambiaremos la proporción de bolas negras en la bolsa $\mu$ por la proporción de fallos de la función estimadora $h$ en todo el conjunto de entrada $\mathcal{X}$. Llamaremos a esta proporción el error fuera de la muestra. Siendo $\mathcal{P}$ una probabilidad basada en la ditribución de $\mathcal{X}$ que se usa para muestrear los datos $x$, definimos el error de fuera de la muestra como:

\[
\ E_{out}(h)= \mathcal{P}\left[ h(x) \neq f(x)\right].
\]

De modo similar, el equivalente a la proporción de bolas negras en la muestra $\nu$ tiene su equivalente en la proporción de errores en el conjunto de aprendizaje $\mathcal{D}$. A esta proporción la llamaremos error en la muestra. Siendo $[\![$condición$]\!]=1$ si la condición es cierta y $[\![$condición$]\!]=0$ si es falsa, el error en la muestra se define como:

\[
\ E_{in}(h) = \frac{1}{N} \sum_{n=1}^N [\![h(x) \neq f(x)]\!].
\]

Entonces la inecuación de Hoeffding se puede reescribir como:

\[
\ \mathbb{P}\left[ \mid E_{in}(h) - E_{out}(h) \mid > \epsilon \right] \leq 2e^{-2\epsilon^2 N} \qquad \textrm{para todo} \  \epsilon > 0.
\]

Esto nos permite decir que podemos aprender fuera de la muestra. Pero para ello, vamos a necesitar un gran número de datos de entrada.\\

Este proceso en realidad es una simplificación del problema real, pues al introducir en el problema el espacio de funciones $\mathcal{H}$ la cota se tiene que recalcular para considerar que tenemos más de una función $h$, aumentando la necesidad de número de muestras para poder obtener la misma seguridad. Además hay que realizar un estudio más preciso cuando el espacio de funciones $\mathcal{H}$ es infinito, utilizando para ello, entre otros elementos, la teoría de Vapnik-Chervonenskis. Sin embargo, dada la naturaleza simplemente introductiva de esta sección, vamos a quedarnos con esta versión simplificada, pues el concepto es el mismo que hemos desarrollado aquí, incluyendo la característica de un conjunto de funciones $\mathcal{H}$ infinito.\\

\subsection{Ruido y sobreaprendizaje}


La situación que hemos estudiado es un caso ideal. En la aplicación de estos conceptos a los casos del mundo real, tenemos que adaptarnos a situaciones que no son tan idílicas. Por ello, terminaremos esta sección introduciendo una par de conceptos para acercar esta teoría a su aplicación a los problemas del mundo real.\\

La primera noción es sobre la naturaleza de la función que queremos aprender. Hasta ahora, hemos considerado que la función a estudiar tiene completamente definida la salida para un dato de entrada. Pero en muchas situaciones reales, esto no es así, pues hay ruido que hace que la salida de la función no esté completamente definida por la entrada.\\ 

La segunda noción es el sobreaprendizaje. Por sobreaprendizaje entendemos que nuestra aproximación se pega tanto a los datos de aprendizaje que acaba obteniendo una mala generalización. Esto suele suceder cuando la familia de funciones $\mathcal{H}$ tiene más grados de libertad de los necesitados para aprender la función, y por tanto más posibilidades de aprendizaje de las necesarias, lo que le permite adaptarse a las peculiaridades de la muestra, empeorando por tanto su adaptación general. Estos errores pueden ser de todo tipo: ruido, datos raros e incluso fallo humano en la introducción de los datos.\\
